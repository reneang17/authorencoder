{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect_langs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "data_dir = '../data/wrangled/'\n",
    "data_file = 'wrangled_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir + data_file,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wspace_schars(review, chars_to_keep=\".,'\\n\" , no_white_space = True, no_newlines= True):\n",
    "    \"\"\"\n",
    "    Function to formar expressions\n",
    "    \"\"\"\n",
    "    \n",
    "    to_keep= \"\"\n",
    "    for i in chars_to_keep:\n",
    "        to_keep+= i+'|'\n",
    "   \n",
    "    rep_special_chars= re.compile(\"[^\\w\\n|\"+ (to_keep[:-1])+ \"]|_\") \n",
    "    \n",
    "    text=rep_special_chars.sub(' ', review) # Subs special charas by white space except chars_to_keep\n",
    "    if no_white_space:\n",
    "        text = re.sub('\\n+', '\\n',text) # Remove consecutive breaklines\n",
    "    if no_newlines:\n",
    "        text = re.sub(' +', ' ',text) # Remove consecutive white space\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To those who want to try a different way of formating \n",
      " \n",
      "'''''\n",
      "'a a'\n",
      "a a's\n",
      "b b.....\n",
      ",.... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_string = \"\"\"\n",
    "To those who want to try a different way of formating:\n",
    "!@#$%^&*()_+\n",
    "'''''\n",
    "'a____a'\n",
    "\n",
    "\n",
    "a____a's\n",
    "\n",
    "\n",
    "\n",
    "b   b.....\n",
    ",..../?\n",
    "\"\"\"\n",
    "print(wspace_schars(test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df.content.apply(lambda x: wspace_schars(x, \n",
    "            chars_to_keep=\".,'\\n?!\", no_white_space = False, no_newlines= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longest poems\n",
    "TOP_N = 12000\n",
    "longest_poems_ids =df.length_in_words.sort_values(ascending=False)[:TOP_N]\n",
    "longest_poems_ids = [i[0] for i in longest_poems_ids.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us count from which authors we have enough material\n",
    "NEED_WORDS_PER_AUTHOR = 2500\n",
    "repeated_authors = df.groupby('author')['length_in_words'].sum()\n",
    "repeated_authors_list= [i[0] for i in repeated_authors[repeated_authors > NEED_WORDS_PER_AUTHOR].items()]\n",
    "\n",
    "df = df[df.author.isin(repeated_authors_list)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Explore best poems for training\n",
    "- Measures word lenght, \n",
    "- Partitions accordingly,\n",
    "- create pandas series,\n",
    "- appends accordingly,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_INTO = 100\n",
    "\n",
    "def poem_fragments(poem_series, split_into=SPLIT_INTO):\n",
    "    \"\"\" \n",
    "    Gets wordlend of a poem,  \n",
    "    if larger than SPLIT_INTO partions into next paragraph\n",
    "    return author, title and poem broken in this way\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    poem = poem_series\n",
    "    poem_author = poem.author\n",
    "    poem_title = poem.title\n",
    "    poem_content = poem.content\n",
    "    poem_pa= poem.content.split('.\\n')\n",
    "    i=0\n",
    "    while ((i+1)!=(len(poem_pa))):\n",
    "        if not (len(poem_pa[i].split())<SPLIT_INTO):\n",
    "            if poem_pa[i][-1]!='.': poem_pa[i]=poem_pa[i]+'.'\n",
    "            #print('FINAL')\n",
    "            #print(poem_pa[i])\n",
    "            i+=1        \n",
    "        else:\n",
    "            #print('BEFORE')\n",
    "            #print(poem_pa[i])\n",
    "            poem_pa[i] =  poem_pa[i]+'.\\n'+poem_pa[i+1]\n",
    "        \n",
    "            del poem_pa[i+1]\n",
    "    return  (poem_author, poem_title  ,poem_pa) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[:0].drop(columns= ['poetry_foundation_id','length_in_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    (author, title, poem_pa  )= poem_fragments( df.iloc[i])\n",
    "    for j in poem_pa:\n",
    "        df_final=df_final.append(pd.Series({'author': author, 'title':title, 'content':j }),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_list= [i[0] for i in df_final.author.value_counts().items()]\n",
    "authors_count_list= [i[1] for i in df_final.author.value_counts().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_dict = {j:i for i,j in enumerate(authors_list)}\n",
    "df_final['author_label'] = df_final.author.apply(lambda x: author_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_dir= '../data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take top hundred authors, ignore the first to no\n",
    "MAX_N_AUTHORS= 10\n",
    "MAX_LIST= authors_list[:MAX_N_AUTHORS]\n",
    "df_final[df_final.author.isin(MAX_LIST)].drop(columns= ['author', 'title']).to_json(process_dir+'top_10_authors.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take top hundred authors, ignore the first to no\n",
    "MAX_N_AUTHORS= 90\n",
    "MAX_LIST= authors_list[:MAX_N_AUTHORS]\n",
    "df_final[df_final.author.isin(MAX_LIST)].drop(columns= ['author', 'title']).to_json(process_dir+'top_90_authors.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take top hundred authors, ignore the first to no\n",
    "MAX_N_AUTHORS= 100\n",
    "MIN_N_AUTHORS = 90\n",
    "MAX_LIST= authors_list[MIN_N_AUTHORS:MAX_N_AUTHORS]\n",
    "df_final[df_final.author.isin(MAX_LIST)].drop(columns= ['author', 'title']).to_json(process_dir+'bottom_10_authors.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting 10 longest poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1418, 12412, 14512, 11631, 5112, 66, 12259, 6929, 6180, 2967]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LONGEST_N= 10\n",
    "longest_list= [i[0] for i in df.length_in_words.sort_values(ascending=False).items()][:LONGEST_N]\n",
    "longest_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23130, 15765, 9713, 9450, 7857, 7779, 7444, 7011, 6103, 6048]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[1] for i in df.length_in_words.sort_values(ascending=False).items()][:LONGEST_N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df= df[df.index.isin(longest_list)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_longest10 = _df[:0].drop(columns= ['poetry_foundation_id','length_in_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(_df)):\n",
    "    (author,title, poem_pa  )= poem_fragments( _df.iloc[i])\n",
    "    for j in poem_pa:\n",
    "        df_longest10=df_longest10.append(pd.Series({'author': author, 'title':title, 'content':j }),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john_dryden': 0,\n",
       " 'robert_pinsky': 1,\n",
       " 'anne_carson': 2,\n",
       " 'alfred_lord_tennyson': 3,\n",
       " 'allen_ginsberg': 4,\n",
       " 'philip_whalen': 5,\n",
       " 'matthew_arnold': 6,\n",
       " 'walt_whitman': 7,\n",
       " 'william_shakespeare': 8,\n",
       " 'anonymous': 9}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_dict = {j:i for i,j in enumerate(df_longest10.author.unique())}\n",
    "author_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_longest10['author_label'] = df_longest10.author.apply(lambda x: author_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_longest10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_longest10.drop(columns= ['author', 'title']).to_json(process_dir+'longest_poems.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
