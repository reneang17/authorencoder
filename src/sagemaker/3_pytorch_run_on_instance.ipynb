{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic comment classification convolutional model run on instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = './data_to_s3' # The folder where data/iterators/vocab are stored\n",
    "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
    "    print('Go back and create data at directory: ', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sagemaker\n",
    "\n",
    "#sagemaker_session = sagemaker.Session()\n",
    "#bucket = sagemaker_session.default_bucket()\n",
    "#prefix = 'toxic/data'\n",
    "#role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build and Train the PyTorch Model\n",
    "\n",
    "In the XGBoost notebook we discussed what a model is in the SageMaker framework. In particular, a model comprises three objects\n",
    "\n",
    " - Model Artifacts,\n",
    " - Training Code, and\n",
    " - Inference Code,\n",
    " \n",
    "each of which interact with one another. In the XGBoost example we used training and inference code that was provided by Amazon. Here we will still be using containers provided by Amazon with the added benefit of being able to include our own custom code.\n",
    "\n",
    "We will start by implementing our own neural network in PyTorch along with a training script. For the purposes of this project we have provided the necessary model object in the `model.py` file, inside of the `train` folder. You can see the provided implementation by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn.functional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mCNN\u001b[39;49;00m(nn.Module):\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \r\n",
      "                 dropout, pad_idx):\r\n",
      "        \r\n",
      "        \u001b[36msuper\u001b[39;49;00m().\u001b[32m__init__\u001b[39;49;00m()\r\n",
      "        \r\n",
      "        \u001b[36mself\u001b[39;49;00m.embedding = nn.Embedding(vocab_size, embedding_dim)\r\n",
      "        \r\n",
      "        \u001b[36mself\u001b[39;49;00m.convs = nn.ModuleList([\r\n",
      "                                    nn.Conv2d(in_channels = \u001b[34m1\u001b[39;49;00m, \r\n",
      "                                              out_channels = n_filters, \r\n",
      "                                              kernel_size = (fs, embedding_dim)) \r\n",
      "                                    \u001b[34mfor\u001b[39;49;00m fs \u001b[35min\u001b[39;49;00m filter_sizes\r\n",
      "                                    ])\r\n",
      "        \r\n",
      "        \u001b[36mself\u001b[39;49;00m.fc = nn.Linear(\u001b[36mlen\u001b[39;49;00m(filter_sizes) * n_filters, output_dim)\r\n",
      "        \r\n",
      "        \u001b[36mself\u001b[39;49;00m.dropout = nn.Dropout(dropout)\r\n",
      "        \r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, text):\r\n",
      "        \r\n",
      "        \u001b[37m#text = [sent len, batch size]\u001b[39;49;00m\r\n",
      "        \r\n",
      "        text = text.permute(\u001b[34m1\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m)\r\n",
      "                \r\n",
      "        \u001b[37m#text = [batch size, sent len]\u001b[39;49;00m\r\n",
      "        \r\n",
      "        embedded = \u001b[36mself\u001b[39;49;00m.embedding(text)\r\n",
      "                \r\n",
      "        \u001b[37m#embedded = [batch size, sent len, emb dim]\u001b[39;49;00m\r\n",
      "        \r\n",
      "        embedded = embedded.unsqueeze(\u001b[34m1\u001b[39;49;00m)\r\n",
      "        \r\n",
      "        \u001b[37m#embedded = [batch size, 1, sent len, emb dim]\u001b[39;49;00m\r\n",
      "        \r\n",
      "        conved = [F.relu(conv(embedded)).squeeze(\u001b[34m3\u001b[39;49;00m) \u001b[34mfor\u001b[39;49;00m conv \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.convs]\r\n",
      "            \r\n",
      "        \u001b[37m#conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\u001b[39;49;00m\r\n",
      "        \r\n",
      "        pooled = [F.max_pool1d(conv, conv.shape[\u001b[34m2\u001b[39;49;00m]).squeeze(\u001b[34m2\u001b[39;49;00m) \u001b[34mfor\u001b[39;49;00m conv \u001b[35min\u001b[39;49;00m conved]\r\n",
      "        \r\n",
      "        \u001b[37m#pooled_n = [batch size, n_filters]\u001b[39;49;00m\r\n",
      "        \r\n",
      "        cat = \u001b[36mself\u001b[39;49;00m.dropout(torch.cat(pooled, dim = \u001b[34m1\u001b[39;49;00m))\r\n",
      "\r\n",
      "        \u001b[37m#cat = [batch size, n_filters * len(filter_sizes)]\u001b[39;49;00m\r\n",
      "            \r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.fc(cat)\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize train/model_nlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utilities to load iterators\n",
    "from train.utils import Data_iterator, Test_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator_train = Data_iterator('train')\n",
    "iterator_val = Data_iterator('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    preds_list=[]\n",
    "    labels_list= []\n",
    " \n",
    "    iterations=0\n",
    "    for batch in iterator:\n",
    "        iterations+=1\n",
    "        \n",
    "        batch_X, batch_y = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch_X).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch_y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        preds_list+=[torch.sigmoid(predictions).detach().numpy()]\n",
    "        labels_list+=[batch_y.numpy()]\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "    return epoch_loss / iterations, roc_auc_score(np.vstack(labels_list), np.vstack(preds_list))\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    preds_list=[]\n",
    "    labels_list= []\n",
    "    epoch_acc=[]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        iterations = 0\n",
    "        for batch in iterator:\n",
    "            iterations+=1\n",
    "            \n",
    "            batch_X, batch_y = batch\n",
    "            \n",
    "            predictions = model(batch_X).squeeze(1)\n",
    "            \n",
    "            #batch_labels = torch.stack([getattr(batch, y) for y in yFields]) #transpose?\n",
    "            #batch_labels = torch.transpose(batch_labels,0,1)\n",
    "            \n",
    "            loss = criterion(predictions, batch_y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            preds_list+=[torch.sigmoid(predictions).detach().numpy()]\n",
    "            labels_list+=[batch_y.numpy()]\n",
    "        \n",
    "            #if i%64==0:\n",
    "            #    epoch_acc += [roc_auc(np.vstack(preds_list), np.vstack(batch_labels))]\n",
    "            #    preds_list=[]\n",
    "            #    labels_list= []\n",
    "        \n",
    "    return epoch_loss / iterations, roc_auc_score(np.vstack(labels_list),np.vstack(preds_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.model_nlp import CNN\n",
    "\n",
    "INPUT_DIM =  20002 # len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3,4]\n",
    "OUTPUT_DIM = 6\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = 1 # TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, \n",
    "            FILTER_SIZES ,OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
       "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.2161, -0.4992,  0.4119,  ...,  0.0555,  0.1958,  0.8141],\n",
       "        [-0.3152,  0.3180,  0.0812,  ..., -0.0243,  0.2619, -0.6031],\n",
       "        [-0.4617, -0.3862, -0.4489,  ..., -0.8185,  0.4885,  0.4705]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "with open(os.path.join('./data_to_s3','untrained_vocab_vectors_list.json'), 'r') as f:\n",
    "    vocab_vectors = json.load(f)\n",
    "pretrained_embeddings = torch.tensor(vocab_vectors)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
      "        ...,\n",
      "        [ 0.2161, -0.4992,  0.4119,  ...,  0.0555,  0.1958,  0.8141],\n",
      "        [-0.3152,  0.3180,  0.0812,  ..., -0.0243,  0.2619, -0.6031],\n",
      "        [-0.4617, -0.3862, -0.4489,  ..., -0.8185,  0.4885,  0.4705]])\n"
     ]
    }
   ],
   "source": [
    "# Setting unknown token and padding to zero\n",
    "model.embedding.weight.data[0] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[1] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 3m 38s\n",
      "\tTrain Loss: 0.083 | Train Acc: 88.46%\n",
      "\t Val. Loss: 0.052 |  Val. Acc: 96.33%\n",
      "Epoch: 02 | Epoch Time: 3m 36s\n",
      "\tTrain Loss: 0.055 | Train Acc: 96.26%\n",
      "\t Val. Loss: 0.048 |  Val. Acc: 97.54%\n",
      "Epoch: 03 | Epoch Time: 3m 36s\n",
      "\tTrain Loss: 0.049 | Train Acc: 97.56%\n",
      "\t Val. Loss: 0.047 |  Val. Acc: 97.99%\n",
      "Epoch: 04 | Epoch Time: 3m 37s\n",
      "\tTrain Loss: 0.045 | Train Acc: 98.03%\n",
      "\t Val. Loss: 0.047 |  Val. Acc: 98.06%\n"
     ]
    }
   ],
   "source": [
    "model.embedding.weight.requires_grad = True\n",
    "\n",
    "\n",
    "N_EPOCHS = 4\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, iterator_train, optimizer, criterion)\n",
    "\n",
    "    valid_loss, valid_acc = evaluate(model, iterator_val, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), './model_state/model_state.pt')\n",
    "\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
